name: vpp-build-test-merge
# This workflow can be triggered ONLY by other workflows (workflow_call)

on:
  # Invocation from other workflows
  workflow_call:
    inputs:
      is_build:
        description: 'Run only build phase (no tests, no merge)'
        required: false
        default: false
        type: boolean
      is_verify:
        description: 'Run build + test phases (skip merge)'
        required: false
        default: false
        type: boolean
      is_merge:
        description: 'Run build + merge phases (skip tests)'
        required: false
        default: false
        type: boolean
      build_type:
        description: 'Build type selection (debug, release, or both)'
        required: false
        default: 'both'
        type: string
      branch:
        description: 'Branch to verify (master, stable/YYMM)'
        required: true
        default: 'master'
        type: string

defaults:
  run:
    shell: bash

jobs:
  vpp-verify:
    runs-on:
      - self-hosted
      - nomad
      - fdio:arch=${{ matrix.executor_arch }}
      - fdio:class=builder
      - fdio:namespace=sandbox
      - fdio:os=${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: ['ubuntu2404', 'ubuntu2204', 'debian12']
        executor_arch: ['x86_64', 'aarch64']
        build_type: ${{ (inputs.build_type == 'debug' || github.event.inputs.build_type == 'debug') && fromJson('["debug"]') || (inputs.build_type == 'release' || github.event.inputs.build_type == 'release') && fromJson('["release"]') || fromJson('["debug", "release"]') }}
        exclude:
          # Exclude debian12 on aarch64 for all builds
          - os: 'debian12'
            executor_arch: 'aarch64'
          # Exclude non-ubuntu2204 OS for debug builds
          - build_type: 'debug'
            os: 'ubuntu2404'
          - build_type: 'debug'
            os: 'debian12'
          # Exclude aarch64 architecture for debug builds
          - build_type: 'debug'
            executor_arch: 'aarch64'

    env:
      CACHE_DATE: ${{ github.run_id }}
      CCACHE_DIR: /scratch/ccache/${{ matrix.os }}-${{ matrix.executor_arch }}
      DOCKER_TEST: 1
      EXECUTOR_ARCH: ${{ matrix.executor_arch }}
      JOB_NAME: ${{ github.job }}-${{ inputs.branch == 'master' && 'master' || inputs.branch == 'stable/2502' && '2502' || '2506' }}-${{ matrix.os }}-${{ matrix.executor_arch }}
      MAKE_PARALLEL_JOBS: 16
      MAKE_TEST_OS: ${{ matrix.os == 'ubuntu2204' && 'ubuntu-22.04' || matrix.os == 'ubuntu2404' && 'ubuntu-24.04' || 'debian-12' }}
      MAKE_TEST_MULTIWORKER_OS: 'debian-12'
      SHM_SIZE: ${{ matrix.executor_arch == 'aarch64' && '4096M' || '2048M' }}
      STREAM: ${{ inputs.branch == 'master' && 'master' || inputs.branch == 'stable/2502' && '2502' || '2506' }}
      TEST_RETRIES: 3
      VPPAPIGEN_TEST_OS: ${{ matrix.os == 'ubuntu2204' && 'ubuntu-22.04' || matrix.os == 'ubuntu2404' && 'ubuntu-24.04' || 'debian-12' }}
      VPP_SRC_DIR: /scratch/docker-build/vpp
      WORKSPACE: ${{ github.workspace }}

    steps:
      - name: Determine phase selection (Build/Test/Merge)
        run: |
          BUILD_INPUT='${{ inputs.is_build || github.event.inputs.is_build }}'
          TEST_INPUT='${{ inputs.is_verify || github.event.inputs.is_verify }}'
          MERGE_INPUT='${{ inputs.is_merge || github.event.inputs.is_merge }}'
          RUN_TEST_PHASE=true
          RUN_MERGE_PHASE=true
          # Precedence: Build > Test > Merge (if multiple true)
          if [[ "$BUILD_INPUT" == 'true' ]]; then
            RUN_TEST_PHASE=false
            RUN_MERGE_PHASE=false
            PHASE_MODE='BUILD'
          elif [[ "$TEST_INPUT" == 'true' ]]; then
            RUN_TEST_PHASE=true
            RUN_MERGE_PHASE=false
            PHASE_MODE='TEST'
          elif [[ "$MERGE_INPUT" == 'true' ]]; then
            RUN_TEST_PHASE=false
            RUN_MERGE_PHASE=true
            PHASE_MODE='MERGE'
          else
            PHASE_MODE='FULL'
          fi
          echo "RUN_TEST_PHASE=${RUN_TEST_PHASE}" >> $GITHUB_ENV
          echo "RUN_MERGE_PHASE=${RUN_MERGE_PHASE}" >> $GITHUB_ENV
          echo "PHASE_MODE=${PHASE_MODE}" >> $GITHUB_ENV
          echo "Selected phase mode: ${PHASE_MODE} (RUN_TEST_PHASE=${RUN_TEST_PHASE} RUN_MERGE_PHASE=${RUN_MERGE_PHASE})"

      - name: Setup Environment
        uses: pmikus/.github/.github/actions/setup_executor_env@main

      - name: Setup Docker Environment
        run: |
          if [ -n ${DOCKER_TEST} ] ; then
            # for 4 cores:
            # framework.VppTestCase.MIN_REQ_SHM + (num_cores * framework.VppTestCase.SHM_PER_PROCESS)
            # 1073741824 == 1024M (1073741824 >> 20)
            MEM=1024M
            if [[ ${MAKE_PARALLEL_JOBS} == '16' ]]
            then
                # arm build are running with 16 cores, empirical evidence shows
                # that 2048M is enough
                MEM=2048M
            fi
            sudo mount -o remount /dev/shm -o size=${MEM} || true
                  echo "/dev/shm remounted with size='${MEM}'"
          fi

      - name: Install VPP external dependencies
        run: |
          set -o pipefail

          SCRIPT_NAME="setup_vpp_ext_deps"
          START_TS=$(date +%s)

          #--------------------- Configuration / Env ---------------------#
          : "${STREAM:=master}"                 # default stream
          : "${VERBOSE:=0}"                     # set 1 for verbose logs
          : "${DRY_RUN:=0}"                     # set 1 to only simulate actions
          : "${DOWNLOADS_DIR:=/root/Downloads}" # override cache dir
          : "${APT_RETRIES:=3}"                 # retry count
          : "${APT_RETRY_DELAY:=3}"             # initial backoff seconds
          : "${SUMMARY_JSON:=1}"                # output JSON summary line

          LOG_PREFIX="[${SCRIPT_NAME}]"
          ACTION="none"
          RESULT="unknown"
          CACHED=false
          PKG_VERSION=""
          PKG_ARCH=""
          SKIP_REASON=""
          ADDED_LIST_FILE=""  # track repo list to remove

          #--------------------- Logging Helpers -------------------------#
          log() { printf '%s %s\n' "$LOG_PREFIX" "$*" ; }
          logv() { [ "$VERBOSE" = "1" ] && log "$*" || true; }
          warn() { printf '%s WARN: %s\n' "$LOG_PREFIX" "$*" >&2; }
          err()  { printf '%s ERROR: %s\n' "$LOG_PREFIX" "$*" >&2; }

          json_summary() {
            [ "$SUMMARY_JSON" = "1" ] || return 0
            local end_ts dur
            end_ts=$(date +%s)
            dur=$(( end_ts - START_TS ))
            printf '{"script":"%s","stream":"%s","os":"%s","action":"%s","result":"%s","cached":%s,"version":"%s","arch":"%s","duration_sec":%s,"skip_reason":"%s"}\n' \
              "$SCRIPT_NAME" "$STREAM" "$OS_ID" "$ACTION" "$RESULT" "$CACHED" "${PKG_VERSION}" "${PKG_ARCH}" "$dur" "${SKIP_REASON}" || true
          }

          finish() { json_summary; exit 0; }
          trap 'RESULT="error"; json_summary' EXIT

          log "---> ${SCRIPT_NAME}: starting (STREAM=$STREAM VERBOSE=$VERBOSE DRY_RUN=$DRY_RUN)"

          #--------------------- Validation ------------------------------#
          if ! printf '%s' "$STREAM" | grep -Eq '^(master|stable/[0-9]{4})$'; then
            warn "STREAM '$STREAM' does not match expected patterns; proceeding anyway (treated as custom)."
          fi

          #--------------------- OS Detection ----------------------------#
          OS_ID=$(grep '^ID=' /etc/os-release 2>/dev/null | cut -f2- -d= | sed -e 's/"//g') || OS_ID="unknown"
          OS_VERSION_ID=$(grep '^VERSION_ID=' /etc/os-release 2>/dev/null | cut -f2- -d= | sed -e 's/"//g') || OS_VERSION_ID="unknown"
          OS_ID_LC=${OS_ID,,}
          logv "Detected OS: ${OS_ID} ${OS_VERSION_ID}"

          case "$OS_ID_LC" in
            ubuntu|debian) : ;;
            *) SKIP_REASON="unsupported_os"; warn "Unsupported OS '$OS_ID' â€“ skipping."; RESULT="skip"; finish ;;
          esac

          #--------------------- Preparation -----------------------------#
          mkdir -p "$DOWNLOADS_DIR" 2>/dev/null || true
          logv "Using downloads cache dir: $DOWNLOADS_DIR"

          REPO_URL="https://packagecloud.io/fdio/${STREAM}"
          INSTALL_URL="https://packagecloud.io/install/repositories/fdio/${STREAM}"
          logv "REPO_URL: $REPO_URL"
          logv "INSTALL_URL: $INSTALL_URL"

          # Global lock to avoid concurrent apt operations (best effort)
          LOCK_FD=99
          LOCK_FILE=/tmp/${SCRIPT_NAME}.lock
          if command -v flock >/dev/null 2>&1; then
            exec {LOCK_FD}>"$LOCK_FILE" || true
            if flock -n $LOCK_FD; then
              logv "Acquired lock $LOCK_FILE"
            else
              logv "Waiting for lock $LOCK_FILE"
              flock $LOCK_FD || true
            fi
          else
            logv "flock not available; continuing without lock"
          fi

          #--------------------- Utility Functions -----------------------#
          retry_cmd() {
            local attempt=1 rc
            while true; do
              "$@" && return 0
              rc=$?
              if [ $attempt -ge "$APT_RETRIES" ]; then
                return $rc
              fi
              local sleep_for=$(( APT_RETRY_DELAY * attempt ))
              warn "Command failed (rc=$rc). Attempt $attempt/$APT_RETRIES. Retrying in ${sleep_for}s: $*"
              sleep "$sleep_for"
              attempt=$(( attempt + 1 ))
            done
          }

          apt_update() {
            [ "$DRY_RUN" = "1" ] && { log "DRY_RUN: apt-get update skipped"; return 0; }
            retry_cmd sudo apt-get update -qq || return $?
          }

          apt_install_pkg() {
            [ "$DRY_RUN" = "1" ] && { log "DRY_RUN: apt-get install $* skipped"; return 0; }
            DEBIAN_FRONTEND=noninteractive retry_cmd sudo apt-get -y \
              -o Dpkg::Use-Pty=0 --no-install-recommends \
              --allow-downgrades --allow-remove-essential --allow-change-held-packages install "$@"
          }

          add_stream_repo_if_needed() {
            if [ "$STREAM" != "master" ]; then
              log "Configuring stream-specific apt repository for '$STREAM'"
              [ "$DRY_RUN" = "1" ] && { log "DRY_RUN: repo setup skipped"; return 0; }
              sudo apt-get -y remove vpp-ext-deps >/dev/null 2>&1 || true
              sudo rm -f /etc/apt/sources.list.d/fdio_master.list || true
              # The packagecloud script handles key and list creation; tolerate empty repo.
              if ! curl --fail --show-error --location --retry 3 --connect-timeout 10 -s "$INSTALL_URL/script.deb.sh" | sudo bash; then
                warn "Repository setup script failed (possibly empty repo). Proceeding (optimization only)."
              else
                # Attempt to capture the list file we added (best effort)
                ADDED_LIST_FILE=$(ls -1t /etc/apt/sources.list.d/fdio_*.list 2>/dev/null | head -1 || true)
                logv "Added list file: $ADDED_LIST_FILE"
              fi
            else
              logv "STREAM is master; using existing default repo configuration if any"
            fi
          }

          remove_added_repo() {
            [ "$DRY_RUN" = "1" ] && return 0
            if [ -n "$ADDED_LIST_FILE" ] && [ -f "$ADDED_LIST_FILE" ]; then
              logv "Removing added repo list $ADDED_LIST_FILE"
              sudo rm -f "$ADDED_LIST_FILE" || true
            else
              # Fall back to broad removal only for safety
              sudo rm -f /etc/apt/sources.list.d/fdio_*.list || true
            fi
          }

          read_pkg_metadata() {
            PKG_VERSION=$(apt-cache show vpp-ext-deps 2>/dev/null | awk '/^Version:/ {print $2; exit}') || PKG_VERSION=""
            PKG_ARCH=$(apt-cache show vpp-ext-deps 2>/dev/null | awk '/^Architecture:/ {print $2; exit}') || PKG_ARCH=""
            [ -n "$PKG_VERSION" ] && logv "Metadata: version=$PKG_VERSION arch=$PKG_ARCH" || logv "No metadata retrieved (maybe empty repo)"
          }

          #----- Use a cache dir so later jobs/steps can reuse it even after container lifecycle ends. ---------##
          cache_pkg_if_present() {
            [ "$DRY_RUN" = "1" ] && return 0
            local deb="/var/cache/apt/archives/vpp-ext-deps_${PKG_VERSION}_${PKG_ARCH}.deb"
            if [ -f "$deb" ]; then
              cp -n "$deb" "$DOWNLOADS_DIR/" 2>/dev/null || true
            fi
          }

          #--------------------- Package Installation from Cache if Present --------------------#
          install_from_cache() {
            local cached_pkg="$DOWNLOADS_DIR/vpp-ext-deps_${PKG_VERSION}_${PKG_ARCH}.deb"
            if [ -f "$cached_pkg" ]; then
              # Validate archive looks sane
              if dpkg-deb --info "$cached_pkg" >/dev/null 2>&1; then
                log "Installing cached package $cached_pkg"
                [ "$DRY_RUN" = "1" ] && { log "DRY_RUN: skip dpkg -i $cached_pkg"; return 0; }
                if sudo dpkg -i "$cached_pkg"; then
                  CACHED=true
                  return 0
                else
                  warn "Cached package install failed; will attempt network install"
                fi
              else
                warn "Cached package invalid; deleting $cached_pkg"
                rm -f "$cached_pkg" || true
              fi
            fi
            return 1
          }

          install_remote() {
            log "Installing vpp-ext-deps from packagecloud"
            apt_install_pkg vpp-ext-deps || return $?
            cache_pkg_if_present
          }

          #--------------------- Main Flow -------------------------------#
          (
            set +e  # still allow manual control
            add_stream_repo_if_needed
            apt_update || true
            read_pkg_metadata
            if [ -n "$PKG_VERSION" ] && install_from_cache; then
              ACTION="install"; RESULT="success"; exit 0
            fi
            if [ -n "$PKG_VERSION" ]; then
              if install_remote; then
                ACTION="install"; RESULT="success"; exit 0
              else
                warn "Remote install attempt failed"
              fi
            else
              warn "Package metadata unavailable (empty or unreachable repo)"
            fi
            ACTION="install"; RESULT="failed"; exit 0  # still success exit for optimization script
          ) || true

          # Cleanup repo references regardless of outcome
          remove_added_repo || true
          apt_update || true

          log "Completed optimization attempt (RESULT=$RESULT CACHED=$CACHED VERSION=$PKG_VERSION)"

          # Adjust RESULT if still unknown
          [ "$RESULT" = "unknown" ] && RESULT="noop"

          # End (always success exit status for optimization nature)
          json_summary
          trap - EXIT
          exit 0

      - name: Build VPP
        timeout-minutes: 60
        run: |
          set -euxo pipefail

          line="*************************************************************************"
          # Don't build anything if this is a merge job being run when
          # the git HEAD id is not the same as the Gerrit New Revision id.
          if [[ ${JOB_NAME} == *merge* ]] && [ -n "${GERRIT_NEWREV:-}" ] &&
                 [ "$GERRIT_NEWREV" != "$GIT_COMMIT" ] ; then
              echo -e "\n$line\nSkipping build. A newer patch has been merged.\n$line\n"
              exit 0
          fi

          OS_ID=$(grep '^ID=' /etc/os-release | cut -f2- -d= | sed -e 's/\"//g')
          OS_VERSION_ID=$(grep '^VERSION_ID=' /etc/os-release | cut -f2- -d= | sed -e 's/\"//g')
          OS_ARCH=$(uname -m)
          DRYRUN="${DRYRUN:-}"
          IS_CSIT_VPP_JOB="${IS_CSIT_VPP_JOB:-}"
          MAKE_PARALLEL_FLAGS="${MAKE_PARALLEL_FLAGS:-}"
          MAKE_PARALLEL_JOBS="${MAKE_PARALLEL_JOBS:-}"
          MAKE_TEST_OS="${MAKE_TEST_OS:-ubuntu-22.04}"
          MAKE_TEST_MULTIWORKER_OS="${MAKE_TEST_MULTIWORKER_OS:-debian-12}"
          VPPAPIGEN_TEST_OS="${VPPAPIGEN_TEST_OS:-${MAKE_TEST_OS}}"
          BUILD_RESULT="SUCCESSFULLY COMPLETED"
          BUILD_ERROR=""
          RETVAL="0"

          if [ -n "${MAKE_PARALLEL_FLAGS}" ] ; then
            echo "Building VPP. Number of cores for build set with" \
                 "MAKE_PARALLEL_FLAGS='${MAKE_PARALLEL_FLAGS}'."
          elif [ -n "${MAKE_PARALLEL_JOBS}" ] ; then
            echo "Building VPP. Number of cores for build set with" \
                 "MAKE_PARALLEL_JOBS='${MAKE_PARALLEL_JOBS}'."
          else
              echo "Building VPP. Number of cores not set," \
                   "using build default ($(grep -c ^processor /proc/cpuinfo))."
          fi

          make_build_test() {
              if ! make UNATTENDED=yes install-dep ; then
                  BUILD_ERROR="FAILED 'make install-dep'"
                  return
              fi
              if ! make UNATTENDED=yes install-ext-deps ; then
                  BUILD_ERROR="FAILED 'make install-ext-deps'"
                  return
              fi
              if [ -f extras/scripts/build_static_vppctl.sh ]; then
                  if ! extras/scripts/build_static_vppctl.sh ; then
                      BUILD_ERROR="FAILED 'extras/scripts/build_static_vppctl.sh'"
                      return
                  fi
              fi
              if ! make UNATTENDED=yes test-dep ; then
                  BUILD_ERROR="FAILED 'make test-dep'"
                  return
              fi
              if ! make UNATTENDED=yes pkg-verify ; then
                  BUILD_ERROR="FAILED 'make pkg-verify'"
                  return
              fi
              if [ "${IS_CSIT_VPP_JOB,,}" == "true" ] ; then
                  # CSIT jobs don't need to run make test
                  return
              fi
              if [ -n "${MAKE_PARALLEL_JOBS}" ] ; then
                  TEST_JOBS="${MAKE_PARALLEL_JOBS}"
                  echo "Testing VPP with ${TEST_JOBS} cores."
              else
                  TEST_JOBS="auto"
                  echo "Testing VPP with automatically calculated number of cores. " \
                       "See test logs for the exact number."
              fi
              if grep -q "${OS_ID}-${OS_VERSION_ID}" <<< "${VPPAPIGEN_TEST_OS}"; then
                  if ! src/tools/vppapigen/test_vppapigen.py ; then
                      BUILD_ERROR="FAILED src/tools/vppapigen/test_vppapigen.py"
                      return
                  fi
              fi
              if grep -q "${OS_ID}-${OS_VERSION_ID}" <<< "${MAKE_TEST_OS}"; then
                  if ! make COMPRESS_FAILED_TEST_LOGS=yes TEST_JOBS="$TEST_JOBS" RETRIES=3 test ; then
                      BUILD_ERROR="FAILED 'make test'"
                      return
                  fi
              else
                  echo "Skip running 'make test' on ${OS_ID}-${OS_VERSION_ID}"
              fi
              if grep -q "${OS_ID}-${OS_VERSION_ID}" <<< "${MAKE_TEST_MULTIWORKER_OS}"; then
                  if git grep -q VPP_WORKER_CONFIG ; then
                      if ! make VPP_WORKER_CONFIG="workers 2" COMPRESS_FAILED_TEST_LOGS=yes \
                              RETRIES=3 TEST_JOBS="$TEST_JOBS" test ; then
                          BUILD_ERROR="FAILED 'make test' with VPP_WORKER_CONFIG='workers 2'"
                          return
                      else
                          echo -e "\n* VPP ${OS_ID^^}-${OS_VERSION_ID}-${OS_ARCH^^}" \
                                  "MULTIWORKER MAKE TEST SUCCESSFULLY COMPLETED\n"
                      fi
                  elif git grep -q VPP_WORKER_COUNT ; then
                      if ! make VPP_WORKER_COUNT="2" COMPRESS_FAILED_TEST_LOGS=yes \
                              RETRIES=3 TEST_JOBS="$TEST_JOBS" test ; then
                          BUILD_ERROR="FAILED 'make test' with VPP_WORKER_CONFIG='workers 2'"
                          return
                      else
                          echo -e "\n* VPP ${OS_ID^^}-${OS_VERSION_ID}-${OS_ARCH^^}" \
                                  "MULTIWORKER MAKE TEST SUCCESSFULLY COMPLETED\n"
                      fi
                  else
                      echo "Skip running MULTIWORKER MAKE TEST on ${OS_ID}-${OS_VERSION_ID}"
                  fi
              else
                  echo "Skip running MULTIWORKER MAKE TEST on ${OS_ID}-${OS_VERSION_ID}"
              fi
          }

          if [ "${DRYRUN,,}" != "true" ] ; then
              make_build_test
          fi
          if [ -n "$BUILD_ERROR" ] ; then
              BUILD_RESULT="$BUILD_ERROR"
              RETVAL="1"
          fi
          echo -e "\n$line\n* VPP ${OS_ID^^}-${OS_VERSION_ID}-${OS_ARCH^^}" \
                  "BUILD $BUILD_RESULT\n$line\n"
          exit $RETVAL
